{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMhXr+iDbOSBbmXoKH+4rgv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubheshswain91/Machine-learning/blob/master/text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_87aviQbKtRQ"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrqlkfxgK7bK"
      },
      "source": [
        "**Text Lowercase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt_X7Gm2K4TZ"
      },
      "source": [
        "def text_lowercase(text):\n",
        "  return text.lower()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZxL-E_6LJgY",
        "outputId": "ee36aa3d-c1cb-4c59-a0c2-e0caf9b5235d"
      },
      "source": [
        "input_str = \"Hey, did you know that the summer break is coming? Amazing right !! It's only 5 more days !!\"\n",
        "print(text_lowercase(input_str))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hey, did you know that the summer break is coming? amazing right !! it's only 5 more days !!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RmzQsz2LcdS"
      },
      "source": [
        "**Remove numbers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d74lnhxELXzh"
      },
      "source": [
        "def remove_numbers(text):\n",
        "  result = re.sub(r'\\d+', '', text)\n",
        "  return result\n",
        "\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrjAbgnqL34A",
        "outputId": "d36914b8-6990-4767-cb8c-1b3e797d8c96"
      },
      "source": [
        "input_str = \"There are 3 balls in this bag, and 12 in the other one.\"\n",
        "print(remove_numbers(input_str))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are  balls in this bag, and  in the other one.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j3fPL8JMHxb"
      },
      "source": [
        "We can convert the decimal numbers into the words using inflect library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpSXhOROMCga"
      },
      "source": [
        "import inflect\n",
        "\n",
        "p = inflect.engine()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzOC1uj9MWNJ"
      },
      "source": [
        "def convert_number(text):\n",
        "  #split strings into tokens\n",
        "\n",
        "  temp_str = text.split(' ')\n",
        "\n",
        "  #intialize empty list\n",
        "  new_string = []\n",
        "\n",
        "  for word in temp_str:\n",
        "    #if word is digit, then convert it to the digit\n",
        "    # numbers and append into the new string list\n",
        "    if word.isdigit():\n",
        "      temp = p.number_to_words(word)\n",
        "      new_string.append(temp)\n",
        "\n",
        "    # append the word as it is\n",
        "    else:\n",
        "      new_string.append(word)\n",
        "\n",
        "   #join the words of new_string to form a string\n",
        "  temp_str = ' '.join(new_string)\n",
        "  return temp_str\n",
        "     "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c5JudejPNbzL",
        "outputId": "e1e75d9c-5442-4ecc-955a-4f21f2ae43a4"
      },
      "source": [
        "input_str = 'There are 31 balls in this bag, and 12 in the other one.'\n",
        "convert_number(input_str)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'There are thirty-one balls in this bag, and twelve in the other one.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7mWWyijOIFM"
      },
      "source": [
        "**Remove punctuation**\n",
        "We remove punctuations so that we don’t have different forms of the same word. If we don’t remove the punctuation, then been. been, been! will be treated separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6loIqdcNndJ"
      },
      "source": [
        "def remove_punctuation(text):\n",
        "  translator = str.maketrans('', '', string.punctuation)\n",
        "  return text.translate(translator)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_TBFsOymOoSy",
        "outputId": "db8861af-6c22-4568-b025-445700160494"
      },
      "source": [
        "input_str = \"Hey, did you know that the summer break is coming? Amazing right !! It's only 5 more days !!\"\n",
        "remove_punctuation(input_str)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hey did you know that the summer break is coming Amazing right  Its only 5 more days '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGDxDnGsPOqL"
      },
      "source": [
        "**Remove whitspaces**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1X9pVY2Orh5"
      },
      "source": [
        "def remove_whitespace(text):\n",
        "  return \" \".join(text.split())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nYpE9oA1PbiJ",
        "outputId": "b2c1b201-003d-45fa-8e6c-2f740eb6879e"
      },
      "source": [
        "input_str = \"   we don't need   the given questions\"\n",
        "print(len(input_str))\n",
        "temp = input_str.split()\n",
        "temp\n",
        "remove_whitespace(input_str)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"we don't need the given questions\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PdmsODQPeMB",
        "outputId": "802b09b4-135b-4c32-edce-8d1cc93f7e53"
      },
      "source": [
        "str = \"we don't need the given questions\"\n",
        "print(len(str))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvChGC_FRdNV"
      },
      "source": [
        "**Remove default stop words**\n",
        "\n",
        "Stopwords are words that do not contribute to the meaning of a sentence. Hence, they can safely be removed without causing any change in the meaning of the sentence. The NLTK library has a set of stopwords and we can use these to remove stopwords from our text and return a list of word tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6ZwU3D6Qlep",
        "outputId": "47a82616-31a3-4dc8-d7cc-d602db7d953a"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyV7612SRyhp"
      },
      "source": [
        "def remove_stopwords(text):\n",
        "  stop_words = set(stopwords.words(\"english\"))\n",
        "  word_tokens = word_tokenize(text)\n",
        "  filtered_text = [word for word in word_tokens if word not in stop_words]\n",
        "  return filtered_text\n",
        "  "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNiRg4dBSRKJ",
        "outputId": "0a33d5e4-8d41-4d58-b35a-744ae4f44f79"
      },
      "source": [
        "example_text = \"This is a sample sentence and we are going to remove the stopwords from this.\"\n",
        "remove_stopwords(example_text)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'sample', 'sentence', 'going', 'remove', 'stopwords', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skpU1jvSTD2M"
      },
      "source": [
        "**Stemming**\n",
        "\n",
        "Stemming is the process of getting the root form of a word. Stem or root is the part to which inflectional affixes (-ed, -ize, -de, -s, etc.) are added. The stem of a word is created by removing the prefix or suffix of a word. So, stemming a word may not result in actual words.\n",
        "\n",
        "Example:\n",
        "\n",
        "books      --->    book\n",
        "looked     --->    look\n",
        "denied     --->    deni\n",
        "flies      --->    fli"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKY6FE4rTdyT"
      },
      "source": [
        "If the text is not in tokens, then we need to convert it into tokens. After we have converted strings of text into tokens, we can convert the word tokens into their root form. There are mainly three algorithms for stemming. These are the Porter Stemmer, the Snowball Stemmer and the Lancaster Stemmer. Porter Stemmer is the most common among them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQAnazccSUix"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYOWxLc4Tixb"
      },
      "source": [
        "def stem_words(text):\n",
        "  word_tokens = word_tokenize(text)\n",
        "  stems = [stemmer.stem(word) for word in word_tokens]\n",
        "  return stems"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_066evyTx80",
        "outputId": "1a7aae43-f595-45c1-81b9-5f3876af39ac"
      },
      "source": [
        "text = 'data science uses scientific methods algorithms and many types of processes'\n",
        "stem_words(text)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data',\n",
              " 'scienc',\n",
              " 'use',\n",
              " 'scientif',\n",
              " 'method',\n",
              " 'algorithm',\n",
              " 'and',\n",
              " 'mani',\n",
              " 'type',\n",
              " 'of',\n",
              " 'process']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LZMGrZZUFil"
      },
      "source": [
        "**Lemmatization**\n",
        "\n",
        "Like stemming, lemmatization also converts a word to its root form. The only difference is that lemmatization ensures that the root word belongs to the language. We will get valid words if we use lemmatization. In NLTK, we use the WordNetLemmatizer to get the lemmas of words. We also need to provide a context for the lemmatization. So, we add the part-of-speech as a parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0hOVDu6Tz56",
        "outputId": "63a75324-89d5-412a-9cf6-69dd8b83a88a"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jME7eqVUVvy"
      },
      "source": [
        "def lemmatize_word(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    # provide context i.e. part-of-speech\n",
        "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens]\n",
        "    return lemmas"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smn1szMdUdAC",
        "outputId": "d75c4edb-8e38-4a48-f6f8-a06914f8b58e"
      },
      "source": [
        "text = 'data science uses scientific methods algorithms and many types of processes'\n",
        "lemmatize_word(text)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data',\n",
              " 'science',\n",
              " 'use',\n",
              " 'scientific',\n",
              " 'methods',\n",
              " 'algorithms',\n",
              " 'and',\n",
              " 'many',\n",
              " 'type',\n",
              " 'of',\n",
              " 'process']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w139scz4Ufxz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
